from flask import Flask, request, abort, jsonify
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import MessageEvent, TextMessage, TextSendMessage
from openai import OpenAI
import os
import threading

# Railwayä»¥å¤–ã®ç’°å¢ƒã§ã¯ .env ã‚’èª­ã¿è¾¼ã‚€
if not os.getenv("RAILWAY_ENVIRONMENT"):
    from dotenv import load_dotenv
    load_dotenv()

app = Flask(__name__)

# ç’°å¢ƒå¤‰æ•°ã®å–å¾—
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN")
LINE_CHANNEL_SECRET = os.getenv("LINE_CHANNEL_SECRET")
OPENAI_ORG_ID = os.getenv("OPENAI_ORG_ID")  # ä»»æ„

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
client = OpenAI(
    api_key=OPENAI_API_KEY,
    organization=OPENAI_ORG_ID if OPENAI_ORG_ID else None
)

# LINE BOT åˆæœŸåŒ–
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# ãƒ¦ãƒ¼ã‚¶ãƒ¼çŠ¶æ…‹ç®¡ç†ï¼ˆã‚¹ãƒ†ãƒƒãƒ—é€²è¡Œç”¨ï¼‰
user_state = {}

# ChatGPTã§ãƒ¬ã‚·ãƒ”ã‚’ç”Ÿæˆ

def generate_recipe_from_gpt(ingredients):
    prompt = f'''
ã‚ãªãŸã¯ç¯€ç´„ä¸Šæ‰‹ãªæ–™ç†ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®é£Ÿæã‚’ä½¿ã£ã¦ã€åˆå¿ƒè€…ã§ã‚‚ç°¡å˜ã«ä½œã‚Œã‚‹ãƒ¬ã‚·ãƒ”ã‚’æ—¥æœ¬èªã§ææ¡ˆã—ã¦ãã ã•ã„ã€‚

ã€ææ–™ã€‘{ingredients}

ğŸ½ï¸ã€æ–™ç†åã€‘  
ğŸ§‚ã€ææ–™ï¼ˆ2äººåˆ†ï¼‰ã€‘  
ğŸ”¥ã€æ‰‹é †ã€‘STEP1ã€œSTEP3ã§ç°¡æ½”ã«  
ğŸ’¡ã€ãƒ¯ãƒ³ãƒã‚¤ãƒ³ãƒˆã€‘

ç¯€ç´„ãƒ»ç°¡å˜ãƒ»ãŠã„ã—ã„ãŒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã™ã€‚
'''
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print("âŒ OpenAIã‚¨ãƒ©ãƒ¼:", repr(e))
        return "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€ãƒ¬ã‚·ãƒ”ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"

# é›‘è«‡å¯¾å¿œ

def generate_free_chat_response(user_text):
    prompt = f"ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„ä¼šè©±ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã«è‡ªç„¶ã«è¿”äº‹ã—ã¦ãã ã•ã„ï¼š\n{user_text}"
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print("âŒ é›‘è«‡å¿œç­”ã‚¨ãƒ©ãƒ¼:", repr(e))
        return "ã†ã¾ãè¿”ã›ãªã‹ã£ãŸã¿ãŸã„ã€ã”ã‚ã‚“ã­ã€‚"

# 3æ—¥åˆ†è²·ã„ç‰©ææ¡ˆ
def suggest_shopping_plan():
    return """
ğŸ›’ 3æ—¥åˆ†ã®ç¯€ç´„ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«ãŠã™ã™ã‚ã®è²·ã„ç‰©ãƒªã‚¹ãƒˆã ã‚ˆï¼

ã€é£Ÿæãƒªã‚¹ãƒˆã€‘
ãƒ»é¶ã‚€ã­è‚‰ 2æš
ãƒ»ã‚­ãƒ£ãƒ™ãƒ„ 1ç‰
ãƒ»åµ 6å€‹
ãƒ»è±†è… 2ä¸
ãƒ»ã‚‚ã‚„ã— 2è¢‹
ãƒ»ã«ã‚“ã˜ã‚“ 2æœ¬
ãƒ»ç‰ã­ã 2å€‹

ğŸ½ï¸ ãƒ¡ãƒ‹ãƒ¥ãƒ¼ææ¡ˆï¼š
1æ—¥ç›®ï¼šé¶ã‚­ãƒ£ãƒ™ãƒ„ç‚’ã‚  
2æ—¥ç›®ï¼šè±†è…ã¨åµã®ä¸­è¯é¢¨ç‚’ã‚  
3æ—¥ç›®ï¼šã‚‚ã‚„ã—ãã°é¢¨ç‚’ã‚

ğŸ“Œ ç„¡é§„ãªãä½¿ã„åˆ‡ã‚Œã¦ã‚³ã‚¹ãƒ‘ã‚‚è‰¯ã„ã‚ˆï¼
"""

# ãŠã‹ãšè¿½åŠ ææ¡ˆ
def suggest_extra_dish():
    return """
äº†è§£ï¼ä»Šã®é£Ÿæã«å°‘ã—è¶³ã™ã ã‘ã§ã€ãŠã‹ãšã‚’å¢—ã‚„ã›ã‚‹ã‚ˆğŸ˜Š

ğŸ›’ è¿½åŠ ã™ã‚‹ãªã‚‰ï¼š
ãƒ»ã¡ãã‚ï¼ˆ100å††ã§4æœ¬ï¼‰
ãƒ»å†·å‡ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼ or ã‚ã‹ã‚

ğŸ³ è¿½åŠ ãƒ¡ãƒ‹ãƒ¥ãƒ¼æ¡ˆï¼š
ãƒ»ã¡ãã‚ã®ç”˜è¾›ç‚’ã‚
ãƒ»ãƒ–ãƒ­ãƒƒã‚³ãƒªãƒ¼ã¨åµã®ã”ã¾ãƒãƒ¨ã‚µãƒ©ãƒ€

å‰¯èœã«ã¡ã‚‡ã†ã©ã„ã„ã—ã€ã‚³ã‚¹ãƒ‘ã‚‚æœ€é«˜ã ã‚ˆâœ¨
"""

# ã‚¹ãƒ†ãƒƒãƒ—é€²è¡Œ
def continue_step(event, state):
    idx = state["step_index"] + 1
    if idx < len(state["steps"]):
        state["step_index"] = idx
        reply = f"STEP{idx}: {state['steps'][idx].strip()}\nğŸ‘‰ ç¶šã‘ã‚‹ã«ã¯ã€æ¬¡ã€ã¨é€ã£ã¦ã­ï¼"
    else:
        reply = "ãŠã¤ã‹ã‚Œã•ã¾ï¼ã“ã‚Œã§ãƒ¬ã‚·ãƒ”å®Œäº†ã ã‚ˆğŸ½ï¸\nã¾ãŸä½•ã‹ä½œã‚ŠãŸããªã£ãŸã‚‰æ•™ãˆã¦ã­ï¼"
        del user_state[event.source.user_id]
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply))

# LINEãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¤ãƒ™ãƒ³ãƒˆ
@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    user_id = event.source.user_id
    text = event.message.text.lower()

    if user_id in user_state and user_state[user_id].get("mode") == "step":
        return continue_step(event, user_state[user_id])

    if "è²·ã„ç‰©" in text or "3æ—¥åˆ†" in text:
        reply_text = suggest_shopping_plan()

    elif "ãŠã‹ãš" in text and ("å¢—ã‚„ã—ãŸã„" in text or "ã‚‚ã†å°‘ã—" in text):
        reply_text = suggest_extra_dish()

    elif "ã‚¹ãƒ†ãƒƒãƒ—ã§" in text:
        recipe = generate_recipe_from_gpt(text)
        steps = recipe.split("STEP")
        if len(steps) > 1:
            user_state[user_id] = {"mode": "step", "steps": steps, "step_index": 1}
            reply_text = f"STEP1: {steps[1].strip()}\nğŸ‘‰ ç¶šã‘ã‚‹ã«ã¯ã€æ¬¡ã€ã¨é€ã£ã¦ã­ï¼"
        else:
            reply_text = recipe

    elif "ã¾ã¨ã‚ã¦" in text:
        reply_text = generate_recipe_from_gpt(text)

    elif any(x in text for x in ["ãƒ¬ã‚·ãƒ”", "é£Ÿæ", "ã¤ãã‚Œã‚‹", "ä½œã‚Œã‚‹", "æ–™ç†", "çŒ®ç«‹", "ã¤ãã‚‹", "ææ–™"]):
        reply_text = generate_recipe_from_gpt(text)

    else:
        reply_text = generate_free_chat_response(text)

    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))

# LINE Webhookã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers.get('X-Line-Signature')
    body = request.get_data(as_text=True)

    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)

    return 'OK'

# ç–é€šç¢ºèªç”¨ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.route("/test-openai", methods=["GET"])
def test_openai():
    try:
        models = client.models.list()
        model_ids = [m.id for m in models.data]
        return jsonify({"status": "ok", "models": model_ids})
    except Exception as e:
        return jsonify({"status": "error", "error": str(e)}), 500

# ãƒ«ãƒ¼ãƒˆç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
@app.route("/", methods=["GET"])
def home():
    return "âœ… Flaskã¯èµ·å‹•ã—ã¦ã„ã¾ã™"

# ã‚¢ãƒ—ãƒªèµ·å‹•
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))
